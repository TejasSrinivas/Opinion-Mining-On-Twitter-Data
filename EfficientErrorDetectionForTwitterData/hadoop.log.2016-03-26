2016-03-26 23:19:35,550 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-03-26 23:19:41,107 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-03-26 23:19:41,110 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-03-26 23:35:29,925 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-03-26 23:35:31,942 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-03-26 23:35:31,943 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-03-26 23:35:32,716 WARN org.apache.hadoop.mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-03-26 23:35:32,892 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 3
2016-03-26 23:35:32,981 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:3
2016-03-26 23:35:33,016 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
2016-03-26 23:35:33,021 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2016-03-26 23:35:33,482 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1664957948_0001
2016-03-26 23:35:34,681 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-03-26 23:35:34,683 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1664957948_0001
2016-03-26 23:35:34,728 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-03-26 23:35:34,779 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-26 23:35:34,792 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-03-26 23:35:35,088 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-03-26 23:35:35,091 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1664957948_0001_m_000000_0
2016-03-26 23:35:35,272 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-26 23:35:35,308 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-26 23:35:35,314 INFO org.apache.hadoop.mapred.MapTask: Processing split: hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweets/FlumeData.1459060167157:0+5477
2016-03-26 23:35:35,707 INFO org.apache.hadoop.mapreduce.Job: Job job_local1664957948_0001 running in uber mode : false
2016-03-26 23:35:35,709 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2016-03-26 23:35:38,428 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-03-26 23:35:38,438 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-03-26 23:35:38,438 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-03-26 23:35:38,438 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-03-26 23:35:38,438 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-03-26 23:35:38,448 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-03-26 23:35:38,890 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-03-26 23:35:38,911 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-03-26 23:35:38,915 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-03-26 23:35:38,915 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 70; bufvoid = 104857600
2016-03-26 23:35:38,917 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
2016-03-26 23:35:38,967 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-03-26 23:35:38,973 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1664957948_0001_m_000000_0 is done. And is in the process of committing
2016-03-26 23:35:38,990 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-03-26 23:35:38,990 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1664957948_0001_m_000000_0' done.
2016-03-26 23:35:38,990 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1664957948_0001_m_000000_0
2016-03-26 23:35:38,991 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1664957948_0001_m_000001_0
2016-03-26 23:35:38,992 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-26 23:35:38,993 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-26 23:35:38,997 INFO org.apache.hadoop.mapred.MapTask: Processing split: hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweets/FlumeData.1459060234833:0+3628
2016-03-26 23:35:39,106 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-03-26 23:35:39,106 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-03-26 23:35:39,107 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-03-26 23:35:39,107 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-03-26 23:35:39,107 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-03-26 23:35:39,110 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-03-26 23:35:39,121 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-03-26 23:35:39,122 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-03-26 23:35:39,122 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-03-26 23:35:39,122 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 56; bufvoid = 104857600
2016-03-26 23:35:39,122 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
2016-03-26 23:35:39,126 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-03-26 23:35:39,128 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1664957948_0001_m_000001_0 is done. And is in the process of committing
2016-03-26 23:35:39,133 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-03-26 23:35:39,135 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1664957948_0001_m_000001_0' done.
2016-03-26 23:35:39,135 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1664957948_0001_m_000001_0
2016-03-26 23:35:39,136 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1664957948_0001_m_000002_0
2016-03-26 23:35:39,137 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-26 23:35:39,138 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-26 23:35:39,140 INFO org.apache.hadoop.mapred.MapTask: Processing split: hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweets/FlumeData.1459060110407:0+1790
2016-03-26 23:35:39,433 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-03-26 23:35:39,434 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-03-26 23:35:39,434 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-03-26 23:35:39,434 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-03-26 23:35:39,434 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-03-26 23:35:39,435 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-03-26 23:35:39,451 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-03-26 23:35:39,452 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-03-26 23:35:39,453 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-03-26 23:35:39,454 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 55; bufvoid = 104857600
2016-03-26 23:35:39,454 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
2016-03-26 23:35:39,481 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-03-26 23:35:39,485 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1664957948_0001_m_000002_0 is done. And is in the process of committing
2016-03-26 23:35:39,490 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-03-26 23:35:39,490 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1664957948_0001_m_000002_0' done.
2016-03-26 23:35:39,490 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1664957948_0001_m_000002_0
2016-03-26 23:35:39,490 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-03-26 23:35:39,511 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-03-26 23:35:39,513 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1664957948_0001_r_000000_0
2016-03-26 23:35:39,526 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-26 23:35:39,529 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-26 23:35:39,551 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2abfe6ca
2016-03-26 23:35:39,581 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=1050129216, maxSingleShuffleLimit=262532304, mergeThreshold=693085312, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-03-26 23:35:39,588 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1664957948_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-03-26 23:35:39,661 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1664957948_0001_m_000002_0 decomp: 59 len: 63 to MEMORY
2016-03-26 23:35:39,667 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 59 bytes from map-output for attempt_local1664957948_0001_m_000002_0
2016-03-26 23:35:39,672 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 59, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->59
2016-03-26 23:35:39,676 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1664957948_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
2016-03-26 23:35:39,678 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1664957948_0001_m_000000_0
2016-03-26 23:35:39,679 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 59, usedMemory ->61
2016-03-26 23:35:39,681 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1664957948_0001_m_000001_0 decomp: 29 len: 33 to MEMORY
2016-03-26 23:35:39,682 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 29 bytes from map-output for attempt_local1664957948_0001_m_000001_0
2016-03-26 23:35:39,682 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 29, inMemoryMapOutputs.size() -> 3, commitMemory -> 61, usedMemory ->90
2016-03-26 23:35:39,682 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-03-26 23:35:39,684 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2016-03-26 23:35:39,686 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2016-03-26 23:35:39,697 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2016-03-26 23:35:39,702 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 12 bytes
2016-03-26 23:35:39,704 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 90 bytes to disk to satisfy reduce memory limit
2016-03-26 23:35:39,706 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 90 bytes from disk
2016-03-26 23:35:39,707 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-03-26 23:35:39,707 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-03-26 23:35:39,708 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 63 bytes
2016-03-26 23:35:39,710 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2016-03-26 23:35:39,723 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-03-26 23:35:39,774 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-03-26 23:35:39,957 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1664957948_0001_r_000000_0 is done. And is in the process of committing
2016-03-26 23:35:39,968 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2016-03-26 23:35:39,970 INFO org.apache.hadoop.mapred.Task: Task attempt_local1664957948_0001_r_000000_0 is allowed to commit now
2016-03-26 23:35:39,988 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1664957948_0001_r_000000_0' to hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweetsoutput/1/_temporary/0/task_local1664957948_0001_r_000000
2016-03-26 23:35:39,993 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-03-26 23:35:39,997 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1664957948_0001_r_000000_0' done.
2016-03-26 23:35:39,997 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1664957948_0001_r_000000_0
2016-03-26 23:35:39,998 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1664957948_0001_r_000001_0
2016-03-26 23:35:40,002 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-26 23:35:40,007 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-26 23:35:40,014 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@426fd2f7
2016-03-26 23:35:40,017 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=1050129216, maxSingleShuffleLimit=262532304, mergeThreshold=693085312, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-03-26 23:35:40,023 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1664957948_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2016-03-26 23:35:40,033 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1664957948_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
2016-03-26 23:35:40,034 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1664957948_0001_m_000002_0
2016-03-26 23:35:40,034 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2016-03-26 23:35:40,042 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1664957948_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
2016-03-26 23:35:40,043 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1664957948_0001_m_000000_0
2016-03-26 23:35:40,043 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->4
2016-03-26 23:35:40,050 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1664957948_0001_m_000001_0 decomp: 35 len: 39 to MEMORY
2016-03-26 23:35:40,051 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 35 bytes from map-output for attempt_local1664957948_0001_m_000001_0
2016-03-26 23:35:40,051 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 35, inMemoryMapOutputs.size() -> 3, commitMemory -> 4, usedMemory ->39
2016-03-26 23:35:40,052 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-03-26 23:35:40,053 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2016-03-26 23:35:40,053 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2016-03-26 23:35:40,056 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2016-03-26 23:35:40,056 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6 bytes
2016-03-26 23:35:40,057 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 39 bytes to disk to satisfy reduce memory limit
2016-03-26 23:35:40,058 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 39 bytes from disk
2016-03-26 23:35:40,058 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-03-26 23:35:40,058 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-03-26 23:35:40,058 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6 bytes
2016-03-26 23:35:40,059 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2016-03-26 23:35:40,084 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1664957948_0001_r_000001_0 is done. And is in the process of committing
2016-03-26 23:35:40,088 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2016-03-26 23:35:40,089 INFO org.apache.hadoop.mapred.Task: Task attempt_local1664957948_0001_r_000001_0 is allowed to commit now
2016-03-26 23:35:40,105 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1664957948_0001_r_000001_0' to hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweetsoutput/1/_temporary/0/task_local1664957948_0001_r_000001
2016-03-26 23:35:40,114 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-03-26 23:35:40,114 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1664957948_0001_r_000001_0' done.
2016-03-26 23:35:40,115 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1664957948_0001_r_000001_0
2016-03-26 23:35:40,115 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1664957948_0001_r_000002_0
2016-03-26 23:35:40,127 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-26 23:35:40,128 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-26 23:35:40,128 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4de9150a
2016-03-26 23:35:40,137 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=1050129216, maxSingleShuffleLimit=262532304, mergeThreshold=693085312, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-03-26 23:35:40,147 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1664957948_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2016-03-26 23:35:40,156 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1664957948_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
2016-03-26 23:35:40,157 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1664957948_0001_m_000002_0
2016-03-26 23:35:40,157 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2016-03-26 23:35:40,160 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1664957948_0001_m_000000_0 decomp: 37 len: 41 to MEMORY
2016-03-26 23:35:40,163 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 37 bytes from map-output for attempt_local1664957948_0001_m_000000_0
2016-03-26 23:35:40,163 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 37, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->39
2016-03-26 23:35:40,171 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1664957948_0001_m_000001_0 decomp: 2 len: 6 to MEMORY
2016-03-26 23:35:40,172 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1664957948_0001_m_000001_0
2016-03-26 23:35:40,172 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 39, usedMemory ->41
2016-03-26 23:35:40,173 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-03-26 23:35:40,174 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2016-03-26 23:35:40,174 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2016-03-26 23:35:40,178 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2016-03-26 23:35:40,178 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6 bytes
2016-03-26 23:35:40,181 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 41 bytes to disk to satisfy reduce memory limit
2016-03-26 23:35:40,181 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 41 bytes from disk
2016-03-26 23:35:40,181 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-03-26 23:35:40,181 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-03-26 23:35:40,182 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 6 bytes
2016-03-26 23:35:40,183 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2016-03-26 23:35:40,233 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1664957948_0001_r_000002_0 is done. And is in the process of committing
2016-03-26 23:35:40,238 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2016-03-26 23:35:40,242 INFO org.apache.hadoop.mapred.Task: Task attempt_local1664957948_0001_r_000002_0 is allowed to commit now
2016-03-26 23:35:40,255 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1664957948_0001_r_000002_0' to hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweetsoutput/1/_temporary/0/task_local1664957948_0001_r_000002
2016-03-26 23:35:40,258 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-03-26 23:35:40,258 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1664957948_0001_r_000002_0' done.
2016-03-26 23:35:40,259 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1664957948_0001_r_000002_0
2016-03-26 23:35:40,260 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1664957948_0001_r_000003_0
2016-03-26 23:35:40,267 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-26 23:35:40,268 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-26 23:35:40,269 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@b68031b
2016-03-26 23:35:40,272 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=1050129216, maxSingleShuffleLimit=262532304, mergeThreshold=693085312, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-03-26 23:35:40,273 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1664957948_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2016-03-26 23:35:40,276 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1664957948_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
2016-03-26 23:35:40,278 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1664957948_0001_m_000002_0
2016-03-26 23:35:40,279 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2016-03-26 23:35:40,292 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1664957948_0001_m_000000_0 decomp: 43 len: 47 to MEMORY
2016-03-26 23:35:40,295 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 43 bytes from map-output for attempt_local1664957948_0001_m_000000_0
2016-03-26 23:35:40,295 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 43, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->45
2016-03-26 23:35:40,297 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1664957948_0001_m_000001_0 decomp: 2 len: 6 to MEMORY
2016-03-26 23:35:40,298 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1664957948_0001_m_000001_0
2016-03-26 23:35:40,298 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 45, usedMemory ->47
2016-03-26 23:35:40,299 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-03-26 23:35:40,300 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2016-03-26 23:35:40,300 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 3 in-memory map-outputs and 0 on-disk map-outputs
2016-03-26 23:35:40,303 INFO org.apache.hadoop.mapred.Merger: Merging 3 sorted segments
2016-03-26 23:35:40,304 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 29 bytes
2016-03-26 23:35:40,304 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 3 segments, 47 bytes to disk to satisfy reduce memory limit
2016-03-26 23:35:40,305 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 47 bytes from disk
2016-03-26 23:35:40,305 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-03-26 23:35:40,305 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-03-26 23:35:40,305 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 29 bytes
2016-03-26 23:35:40,306 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2016-03-26 23:35:40,347 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1664957948_0001_r_000003_0 is done. And is in the process of committing
2016-03-26 23:35:40,353 INFO org.apache.hadoop.mapred.LocalJobRunner: 3 / 3 copied.
2016-03-26 23:35:40,354 INFO org.apache.hadoop.mapred.Task: Task attempt_local1664957948_0001_r_000003_0 is allowed to commit now
2016-03-26 23:35:40,366 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1664957948_0001_r_000003_0' to hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweetsoutput/1/_temporary/0/task_local1664957948_0001_r_000003
2016-03-26 23:35:40,367 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-03-26 23:35:40,367 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1664957948_0001_r_000003_0' done.
2016-03-26 23:35:40,368 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1664957948_0001_r_000003_0
2016-03-26 23:35:40,368 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-03-26 23:35:40,724 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2016-03-26 23:35:40,725 INFO org.apache.hadoop.mapreduce.Job: Job job_local1664957948_0001 completed successfully
2016-03-26 23:35:41,145 INFO org.apache.hadoop.mapreduce.Job: Counters: 38
	File System Counters
		FILE: Number of bytes read=68998
		FILE: Number of bytes written=1897881
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=69057
		HDFS: Number of bytes written=486
		HDFS: Number of read operations=94
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=27
	Map-Reduce Framework
		Map input records=6
		Map output records=6
		Map output bytes=181
		Map output materialized bytes=265
		Input split bytes=441
		Combine input records=0
		Combine output records=0
		Reduce input groups=6
		Reduce shuffle bytes=265
		Reduce input records=6
		Reduce output records=6
		Spilled Records=12
		Shuffled Maps =12
		Failed Shuffles=0
		Merged Map outputs=12
		GC time elapsed (ms)=482
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=1597599744
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=10895
	File Output Format Counters 
		Bytes Written=169
