2016-03-27 00:13:04,659 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-03-27 00:13:06,778 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-03-27 00:13:06,780 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-03-27 00:13:07,499 WARN org.apache.hadoop.mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-03-27 00:13:07,644 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 5
2016-03-27 00:13:07,712 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:5
2016-03-27 00:13:07,730 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
2016-03-27 00:13:07,735 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2016-03-27 00:13:08,116 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local184661189_0001
2016-03-27 00:13:08,891 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-03-27 00:13:08,892 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local184661189_0001
2016-03-27 00:13:08,993 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-03-27 00:13:09,017 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:13:09,025 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-03-27 00:13:09,213 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-03-27 00:13:09,214 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local184661189_0001_m_000000_0
2016-03-27 00:13:09,282 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:13:09,308 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-27 00:13:09,313 INFO org.apache.hadoop.mapred.MapTask: Processing split: hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweets/FlumeData.1459060167157:0+5477
2016-03-27 00:13:09,985 INFO org.apache.hadoop.mapreduce.Job: Job job_local184661189_0001 running in uber mode : false
2016-03-27 00:13:10,000 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2016-03-27 00:13:10,010 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-03-27 00:13:10,011 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-03-27 00:13:10,011 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-03-27 00:13:10,012 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-03-27 00:13:10,012 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-03-27 00:13:10,038 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-03-27 00:13:10,187 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-03-27 00:13:10,196 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-03-27 00:13:10,214 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-03-27 00:13:10,214 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 163; bufvoid = 104857600
2016-03-27 00:13:10,214 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
2016-03-27 00:13:10,229 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-03-27 00:13:10,237 INFO org.apache.hadoop.mapred.Task: Task:attempt_local184661189_0001_m_000000_0 is done. And is in the process of committing
2016-03-27 00:13:10,249 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-03-27 00:13:10,249 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local184661189_0001_m_000000_0' done.
2016-03-27 00:13:10,249 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local184661189_0001_m_000000_0
2016-03-27 00:13:10,250 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local184661189_0001_m_000001_0
2016-03-27 00:13:10,251 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:13:10,252 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-27 00:13:10,254 INFO org.apache.hadoop.mapred.MapTask: Processing split: hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweets/FlumeData.1459060234833:0+3628
2016-03-27 00:13:10,365 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-03-27 00:13:10,365 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-03-27 00:13:10,365 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-03-27 00:13:10,365 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-03-27 00:13:10,365 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-03-27 00:13:10,382 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-03-27 00:13:10,393 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-03-27 00:13:10,393 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-03-27 00:13:10,393 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-03-27 00:13:10,393 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 118; bufvoid = 104857600
2016-03-27 00:13:10,393 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
2016-03-27 00:13:10,412 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-03-27 00:13:10,414 INFO org.apache.hadoop.mapred.Task: Task:attempt_local184661189_0001_m_000001_0 is done. And is in the process of committing
2016-03-27 00:13:10,419 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-03-27 00:13:10,419 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local184661189_0001_m_000001_0' done.
2016-03-27 00:13:10,419 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local184661189_0001_m_000001_0
2016-03-27 00:13:10,419 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local184661189_0001_m_000002_0
2016-03-27 00:13:10,421 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:13:10,422 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-27 00:13:10,424 INFO org.apache.hadoop.mapred.MapTask: Processing split: hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweets/FlumeData.1459061216210:0+1863
2016-03-27 00:13:10,502 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-03-27 00:13:10,503 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-03-27 00:13:10,503 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-03-27 00:13:10,503 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-03-27 00:13:10,504 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-03-27 00:13:10,505 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-03-27 00:13:10,523 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-03-27 00:13:10,523 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-03-27 00:13:10,523 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-03-27 00:13:10,524 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 58; bufvoid = 104857600
2016-03-27 00:13:10,524 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
2016-03-27 00:13:10,563 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-03-27 00:13:10,568 INFO org.apache.hadoop.mapred.Task: Task:attempt_local184661189_0001_m_000002_0 is done. And is in the process of committing
2016-03-27 00:13:10,584 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-03-27 00:13:10,584 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local184661189_0001_m_000002_0' done.
2016-03-27 00:13:10,585 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local184661189_0001_m_000002_0
2016-03-27 00:13:10,585 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local184661189_0001_m_000003_0
2016-03-27 00:13:10,587 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:13:10,589 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-27 00:13:10,592 INFO org.apache.hadoop.mapred.MapTask: Processing split: hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweets/FlumeData.1459060958922:0+1861
2016-03-27 00:13:10,710 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-03-27 00:13:10,711 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-03-27 00:13:10,711 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-03-27 00:13:10,711 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-03-27 00:13:10,711 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-03-27 00:13:10,712 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-03-27 00:13:10,725 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-03-27 00:13:10,726 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-03-27 00:13:10,726 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-03-27 00:13:10,726 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 56; bufvoid = 104857600
2016-03-27 00:13:10,726 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
2016-03-27 00:13:10,735 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-03-27 00:13:10,740 INFO org.apache.hadoop.mapred.Task: Task:attempt_local184661189_0001_m_000003_0 is done. And is in the process of committing
2016-03-27 00:13:10,753 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-03-27 00:13:10,756 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local184661189_0001_m_000003_0' done.
2016-03-27 00:13:10,758 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local184661189_0001_m_000003_0
2016-03-27 00:13:10,758 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local184661189_0001_m_000004_0
2016-03-27 00:13:10,760 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:13:10,761 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-27 00:13:10,772 INFO org.apache.hadoop.mapred.MapTask: Processing split: hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweets/FlumeData.1459060110407:0+1790
2016-03-27 00:13:10,896 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-03-27 00:13:10,897 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-03-27 00:13:10,897 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-03-27 00:13:10,897 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-03-27 00:13:10,897 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-03-27 00:13:10,898 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-03-27 00:13:10,910 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-03-27 00:13:10,911 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-03-27 00:13:10,911 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-03-27 00:13:10,911 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 86; bufvoid = 104857600
2016-03-27 00:13:10,911 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
2016-03-27 00:13:10,916 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-03-27 00:13:10,918 INFO org.apache.hadoop.mapred.Task: Task:attempt_local184661189_0001_m_000004_0 is done. And is in the process of committing
2016-03-27 00:13:10,926 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-03-27 00:13:10,926 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local184661189_0001_m_000004_0' done.
2016-03-27 00:13:10,926 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local184661189_0001_m_000004_0
2016-03-27 00:13:10,926 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-03-27 00:13:10,950 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-03-27 00:13:10,951 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local184661189_0001_r_000000_0
2016-03-27 00:13:10,963 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:13:10,964 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-27 00:13:10,970 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7725aa0c
2016-03-27 00:13:11,007 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-03-27 00:13:11,012 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=1050129216, maxSingleShuffleLimit=262532304, mergeThreshold=693085312, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-03-27 00:13:11,021 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local184661189_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-03-27 00:13:11,107 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local184661189_0001_m_000001_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:13:11,112 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local184661189_0001_m_000001_0
2016-03-27 00:13:11,116 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2016-03-27 00:13:11,122 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local184661189_0001_m_000004_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:13:11,123 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local184661189_0001_m_000004_0
2016-03-27 00:13:11,123 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->4
2016-03-27 00:13:11,125 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local184661189_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:13:11,126 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local184661189_0001_m_000000_0
2016-03-27 00:13:11,126 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 4, usedMemory ->6
2016-03-27 00:13:11,128 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local184661189_0001_m_000003_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:13:11,129 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local184661189_0001_m_000003_0
2016-03-27 00:13:11,129 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 4, commitMemory -> 6, usedMemory ->8
2016-03-27 00:13:11,131 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local184661189_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:13:11,132 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local184661189_0001_m_000002_0
2016-03-27 00:13:11,132 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 5, commitMemory -> 8, usedMemory ->10
2016-03-27 00:13:11,132 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-03-27 00:13:11,133 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:13:11,134 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 0 on-disk map-outputs
2016-03-27 00:13:11,146 INFO org.apache.hadoop.mapred.Merger: Merging 5 sorted segments
2016-03-27 00:13:11,146 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-03-27 00:13:11,147 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 5 segments, 10 bytes to disk to satisfy reduce memory limit
2016-03-27 00:13:11,148 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
2016-03-27 00:13:11,149 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-03-27 00:13:11,149 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-03-27 00:13:11,150 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-03-27 00:13:11,150 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:13:11,219 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-03-27 00:13:11,236 INFO org.apache.hadoop.mapred.Task: Task:attempt_local184661189_0001_r_000000_0 is done. And is in the process of committing
2016-03-27 00:13:11,240 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:13:11,241 INFO org.apache.hadoop.mapred.Task: Task attempt_local184661189_0001_r_000000_0 is allowed to commit now
2016-03-27 00:13:11,253 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local184661189_0001_r_000000_0' to hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweetsoutput/2/_temporary/0/task_local184661189_0001_r_000000
2016-03-27 00:13:11,255 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-03-27 00:13:11,255 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local184661189_0001_r_000000_0' done.
2016-03-27 00:13:11,255 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local184661189_0001_r_000000_0
2016-03-27 00:13:11,255 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local184661189_0001_r_000001_0
2016-03-27 00:13:11,257 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:13:11,258 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-27 00:13:11,258 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@573a6f6d
2016-03-27 00:13:11,260 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=1050129216, maxSingleShuffleLimit=262532304, mergeThreshold=693085312, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-03-27 00:13:11,262 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local184661189_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2016-03-27 00:13:11,266 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local184661189_0001_m_000001_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:13:11,267 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local184661189_0001_m_000001_0
2016-03-27 00:13:11,267 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2016-03-27 00:13:11,270 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local184661189_0001_m_000004_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:13:11,270 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local184661189_0001_m_000004_0
2016-03-27 00:13:11,271 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->4
2016-03-27 00:13:11,273 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local184661189_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:13:11,273 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local184661189_0001_m_000000_0
2016-03-27 00:13:11,274 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 4, usedMemory ->6
2016-03-27 00:13:11,276 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local184661189_0001_m_000003_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:13:11,276 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local184661189_0001_m_000003_0
2016-03-27 00:13:11,276 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 4, commitMemory -> 6, usedMemory ->8
2016-03-27 00:13:11,278 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local184661189_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:13:11,279 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local184661189_0001_m_000002_0
2016-03-27 00:13:11,279 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 5, commitMemory -> 8, usedMemory ->10
2016-03-27 00:13:11,280 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-03-27 00:13:11,281 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:13:11,281 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 0 on-disk map-outputs
2016-03-27 00:13:11,285 INFO org.apache.hadoop.mapred.Merger: Merging 5 sorted segments
2016-03-27 00:13:11,288 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-03-27 00:13:11,289 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 5 segments, 10 bytes to disk to satisfy reduce memory limit
2016-03-27 00:13:11,289 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
2016-03-27 00:13:11,290 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-03-27 00:13:11,290 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-03-27 00:13:11,290 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-03-27 00:13:11,291 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:13:11,306 INFO org.apache.hadoop.mapred.Task: Task:attempt_local184661189_0001_r_000001_0 is done. And is in the process of committing
2016-03-27 00:13:11,311 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:13:11,312 INFO org.apache.hadoop.mapred.Task: Task attempt_local184661189_0001_r_000001_0 is allowed to commit now
2016-03-27 00:13:11,321 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local184661189_0001_r_000001_0' to hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweetsoutput/2/_temporary/0/task_local184661189_0001_r_000001
2016-03-27 00:13:11,323 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-03-27 00:13:11,324 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local184661189_0001_r_000001_0' done.
2016-03-27 00:13:11,324 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local184661189_0001_r_000001_0
2016-03-27 00:13:11,324 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local184661189_0001_r_000002_0
2016-03-27 00:13:11,326 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:13:11,327 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-27 00:13:11,327 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@41936a30
2016-03-27 00:13:11,328 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=1050129216, maxSingleShuffleLimit=262532304, mergeThreshold=693085312, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-03-27 00:13:11,330 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local184661189_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2016-03-27 00:13:11,332 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local184661189_0001_m_000001_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:13:11,338 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local184661189_0001_m_000001_0
2016-03-27 00:13:11,338 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2016-03-27 00:13:11,341 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local184661189_0001_m_000004_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:13:11,342 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local184661189_0001_m_000004_0
2016-03-27 00:13:11,342 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->4
2016-03-27 00:13:11,348 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local184661189_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:13:11,349 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local184661189_0001_m_000000_0
2016-03-27 00:13:11,349 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 4, usedMemory ->6
2016-03-27 00:13:11,351 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local184661189_0001_m_000003_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:13:11,352 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local184661189_0001_m_000003_0
2016-03-27 00:13:11,352 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 4, commitMemory -> 6, usedMemory ->8
2016-03-27 00:13:11,354 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local184661189_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:13:11,355 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local184661189_0001_m_000002_0
2016-03-27 00:13:11,355 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 5, commitMemory -> 8, usedMemory ->10
2016-03-27 00:13:11,355 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-03-27 00:13:11,356 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:13:11,356 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 0 on-disk map-outputs
2016-03-27 00:13:11,359 INFO org.apache.hadoop.mapred.Merger: Merging 5 sorted segments
2016-03-27 00:13:11,359 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-03-27 00:13:11,382 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 5 segments, 10 bytes to disk to satisfy reduce memory limit
2016-03-27 00:13:11,383 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
2016-03-27 00:13:11,384 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-03-27 00:13:11,385 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-03-27 00:13:11,385 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-03-27 00:13:11,391 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:13:11,408 INFO org.apache.hadoop.mapred.Task: Task:attempt_local184661189_0001_r_000002_0 is done. And is in the process of committing
2016-03-27 00:13:11,415 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:13:11,415 INFO org.apache.hadoop.mapred.Task: Task attempt_local184661189_0001_r_000002_0 is allowed to commit now
2016-03-27 00:13:11,431 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local184661189_0001_r_000002_0' to hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweetsoutput/2/_temporary/0/task_local184661189_0001_r_000002
2016-03-27 00:13:11,433 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-03-27 00:13:11,437 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local184661189_0001_r_000002_0' done.
2016-03-27 00:13:11,437 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local184661189_0001_r_000002_0
2016-03-27 00:13:11,438 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local184661189_0001_r_000003_0
2016-03-27 00:13:11,444 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:13:11,446 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-27 00:13:11,446 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2e512f9c
2016-03-27 00:13:11,454 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=1050129216, maxSingleShuffleLimit=262532304, mergeThreshold=693085312, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-03-27 00:13:11,463 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local184661189_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2016-03-27 00:13:11,471 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local184661189_0001_m_000001_0 decomp: 124 len: 128 to MEMORY
2016-03-27 00:13:11,482 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 124 bytes from map-output for attempt_local184661189_0001_m_000001_0
2016-03-27 00:13:11,483 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 124, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->124
2016-03-27 00:13:11,487 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local184661189_0001_m_000004_0 decomp: 90 len: 94 to MEMORY
2016-03-27 00:13:11,492 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 90 bytes from map-output for attempt_local184661189_0001_m_000004_0
2016-03-27 00:13:11,494 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 90, inMemoryMapOutputs.size() -> 2, commitMemory -> 124, usedMemory ->214
2016-03-27 00:13:11,505 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local184661189_0001_m_000000_0 decomp: 171 len: 175 to MEMORY
2016-03-27 00:13:11,509 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 171 bytes from map-output for attempt_local184661189_0001_m_000000_0
2016-03-27 00:13:11,509 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 171, inMemoryMapOutputs.size() -> 3, commitMemory -> 214, usedMemory ->385
2016-03-27 00:13:11,523 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local184661189_0001_m_000003_0 decomp: 60 len: 64 to MEMORY
2016-03-27 00:13:11,524 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 60 bytes from map-output for attempt_local184661189_0001_m_000003_0
2016-03-27 00:13:11,527 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 60, inMemoryMapOutputs.size() -> 4, commitMemory -> 385, usedMemory ->445
2016-03-27 00:13:11,531 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local184661189_0001_m_000002_0 decomp: 62 len: 66 to MEMORY
2016-03-27 00:13:11,535 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 62 bytes from map-output for attempt_local184661189_0001_m_000002_0
2016-03-27 00:13:11,536 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 5, commitMemory -> 445, usedMemory ->507
2016-03-27 00:13:11,538 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-03-27 00:13:11,539 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:13:11,540 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 0 on-disk map-outputs
2016-03-27 00:13:11,542 INFO org.apache.hadoop.mapred.Merger: Merging 5 sorted segments
2016-03-27 00:13:11,542 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 5 segments left of total size: 214 bytes
2016-03-27 00:13:11,545 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 5 segments, 507 bytes to disk to satisfy reduce memory limit
2016-03-27 00:13:11,548 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 503 bytes from disk
2016-03-27 00:13:11,549 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-03-27 00:13:11,549 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-03-27 00:13:11,550 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 454 bytes
2016-03-27 00:13:11,552 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:13:11,839 INFO org.apache.hadoop.mapred.Task: Task:attempt_local184661189_0001_r_000003_0 is done. And is in the process of committing
2016-03-27 00:13:11,843 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:13:11,843 INFO org.apache.hadoop.mapred.Task: Task attempt_local184661189_0001_r_000003_0 is allowed to commit now
2016-03-27 00:13:11,851 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local184661189_0001_r_000003_0' to hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweetsoutput/2/_temporary/0/task_local184661189_0001_r_000003
2016-03-27 00:13:11,853 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-03-27 00:13:11,853 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local184661189_0001_r_000003_0' done.
2016-03-27 00:13:11,853 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local184661189_0001_r_000003_0
2016-03-27 00:13:11,854 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-03-27 00:13:12,008 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2016-03-27 00:13:12,009 INFO org.apache.hadoop.mapreduce.Job: Job job_local184661189_0001 completed successfully
2016-03-27 00:13:12,069 INFO org.apache.hadoop.mapreduce.Job: Counters: 38
	File System Counters
		FILE: Number of bytes read=141239
		FILE: Number of bytes written=2468766
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=111474
		HDFS: Number of bytes written=465
		HDFS: Number of read operations=136
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=29
	Map-Reduce Framework
		Map input records=8
		Map output records=8
		Map output bytes=481
		Map output materialized bytes=617
		Input split bytes=735
		Combine input records=0
		Combine output records=0
		Reduce input groups=8
		Reduce shuffle bytes=617
		Reduce input records=8
		Reduce output records=8
		Spilled Records=16
		Shuffled Maps =20
		Failed Shuffles=0
		Merged Map outputs=20
		GC time elapsed (ms)=342
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=1844219904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=14619
	File Output Format Counters 
		Bytes Written=465
2016-03-27 00:22:14,957 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-03-27 00:22:16,819 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-03-27 00:22:16,821 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-03-27 00:22:17,477 WARN org.apache.hadoop.mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-03-27 00:22:17,619 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 5
2016-03-27 00:22:17,691 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:5
2016-03-27 00:22:17,708 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
2016-03-27 00:22:17,713 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2016-03-27 00:22:18,093 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1614892355_0001
2016-03-27 00:22:18,861 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-03-27 00:22:18,863 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1614892355_0001
2016-03-27 00:22:18,874 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-03-27 00:22:18,906 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:22:18,913 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-03-27 00:22:19,133 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-03-27 00:22:19,134 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1614892355_0001_m_000000_0
2016-03-27 00:22:19,221 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:22:19,241 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-27 00:22:19,246 INFO org.apache.hadoop.mapred.MapTask: Processing split: hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweets/FlumeData.1459060167157:0+5477
2016-03-27 00:22:19,877 INFO org.apache.hadoop.mapreduce.Job: Job job_local1614892355_0001 running in uber mode : false
2016-03-27 00:22:19,891 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2016-03-27 00:22:20,163 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-03-27 00:22:20,164 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-03-27 00:22:20,164 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-03-27 00:22:20,164 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-03-27 00:22:20,165 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-03-27 00:22:20,200 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-03-27 00:22:20,424 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-03-27 00:22:20,432 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-03-27 00:22:20,434 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-03-27 00:22:20,439 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 163; bufvoid = 104857600
2016-03-27 00:22:20,440 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
2016-03-27 00:22:20,454 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-03-27 00:22:20,463 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1614892355_0001_m_000000_0 is done. And is in the process of committing
2016-03-27 00:22:20,497 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-03-27 00:22:20,497 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1614892355_0001_m_000000_0' done.
2016-03-27 00:22:20,497 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1614892355_0001_m_000000_0
2016-03-27 00:22:20,498 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1614892355_0001_m_000001_0
2016-03-27 00:22:20,499 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:22:20,500 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-27 00:22:20,502 INFO org.apache.hadoop.mapred.MapTask: Processing split: hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweets/FlumeData.1459060234833:0+3628
2016-03-27 00:22:20,609 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-03-27 00:22:20,609 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-03-27 00:22:20,609 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-03-27 00:22:20,609 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-03-27 00:22:20,609 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-03-27 00:22:20,610 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-03-27 00:22:20,630 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-03-27 00:22:20,630 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-03-27 00:22:20,630 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-03-27 00:22:20,630 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 118; bufvoid = 104857600
2016-03-27 00:22:20,631 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
2016-03-27 00:22:20,633 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-03-27 00:22:20,635 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1614892355_0001_m_000001_0 is done. And is in the process of committing
2016-03-27 00:22:20,640 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-03-27 00:22:20,641 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1614892355_0001_m_000001_0' done.
2016-03-27 00:22:20,641 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1614892355_0001_m_000001_0
2016-03-27 00:22:20,641 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1614892355_0001_m_000002_0
2016-03-27 00:22:20,643 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:22:20,644 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-27 00:22:20,646 INFO org.apache.hadoop.mapred.MapTask: Processing split: hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweets/FlumeData.1459061216210:0+1863
2016-03-27 00:22:20,749 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-03-27 00:22:20,753 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-03-27 00:22:20,754 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-03-27 00:22:20,754 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-03-27 00:22:20,754 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-03-27 00:22:20,772 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-03-27 00:22:20,786 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-03-27 00:22:20,787 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-03-27 00:22:20,787 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-03-27 00:22:20,787 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 58; bufvoid = 104857600
2016-03-27 00:22:20,787 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
2016-03-27 00:22:20,821 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-03-27 00:22:20,824 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1614892355_0001_m_000002_0 is done. And is in the process of committing
2016-03-27 00:22:20,832 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-03-27 00:22:20,832 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1614892355_0001_m_000002_0' done.
2016-03-27 00:22:20,832 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1614892355_0001_m_000002_0
2016-03-27 00:22:20,832 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1614892355_0001_m_000003_0
2016-03-27 00:22:20,834 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:22:20,835 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-27 00:22:20,837 INFO org.apache.hadoop.mapred.MapTask: Processing split: hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweets/FlumeData.1459060958922:0+1861
2016-03-27 00:22:20,933 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-03-27 00:22:20,952 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-03-27 00:22:20,952 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-03-27 00:22:20,952 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-03-27 00:22:20,953 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-03-27 00:22:20,953 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-03-27 00:22:20,954 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-03-27 00:22:20,967 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-03-27 00:22:20,967 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-03-27 00:22:20,967 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-03-27 00:22:20,967 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 56; bufvoid = 104857600
2016-03-27 00:22:20,967 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
2016-03-27 00:22:20,976 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-03-27 00:22:20,978 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1614892355_0001_m_000003_0 is done. And is in the process of committing
2016-03-27 00:22:20,989 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-03-27 00:22:20,990 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1614892355_0001_m_000003_0' done.
2016-03-27 00:22:20,992 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1614892355_0001_m_000003_0
2016-03-27 00:22:20,992 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1614892355_0001_m_000004_0
2016-03-27 00:22:20,994 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:22:20,995 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-27 00:22:20,998 INFO org.apache.hadoop.mapred.MapTask: Processing split: hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweets/FlumeData.1459060110407:0+1790
2016-03-27 00:22:21,198 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-03-27 00:22:21,200 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-03-27 00:22:21,200 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-03-27 00:22:21,202 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-03-27 00:22:21,202 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-03-27 00:22:21,208 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-03-27 00:22:21,224 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-03-27 00:22:21,225 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-03-27 00:22:21,225 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-03-27 00:22:21,225 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 86; bufvoid = 104857600
2016-03-27 00:22:21,225 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
2016-03-27 00:22:21,232 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-03-27 00:22:21,277 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1614892355_0001_m_000004_0 is done. And is in the process of committing
2016-03-27 00:22:21,290 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-03-27 00:22:21,292 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1614892355_0001_m_000004_0' done.
2016-03-27 00:22:21,292 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1614892355_0001_m_000004_0
2016-03-27 00:22:21,292 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-03-27 00:22:21,321 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-03-27 00:22:21,322 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1614892355_0001_r_000000_0
2016-03-27 00:22:21,353 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:22:21,354 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-27 00:22:21,394 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6b3f07fd
2016-03-27 00:22:21,471 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=1050129216, maxSingleShuffleLimit=262532304, mergeThreshold=693085312, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-03-27 00:22:21,562 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1614892355_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-03-27 00:22:21,649 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1614892355_0001_m_000004_0 decomp: 90 len: 94 to MEMORY
2016-03-27 00:22:21,661 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 90 bytes from map-output for attempt_local1614892355_0001_m_000004_0
2016-03-27 00:22:21,674 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 90, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->90
2016-03-27 00:22:21,684 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1614892355_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:22:21,689 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1614892355_0001_m_000000_0
2016-03-27 00:22:21,690 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 90, usedMemory ->92
2016-03-27 00:22:21,696 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1614892355_0001_m_000003_0 decomp: 60 len: 64 to MEMORY
2016-03-27 00:22:21,699 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 60 bytes from map-output for attempt_local1614892355_0001_m_000003_0
2016-03-27 00:22:21,703 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 60, inMemoryMapOutputs.size() -> 3, commitMemory -> 92, usedMemory ->152
2016-03-27 00:22:21,709 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1614892355_0001_m_000001_0 decomp: 60 len: 64 to MEMORY
2016-03-27 00:22:21,714 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 60 bytes from map-output for attempt_local1614892355_0001_m_000001_0
2016-03-27 00:22:21,716 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 60, inMemoryMapOutputs.size() -> 4, commitMemory -> 152, usedMemory ->212
2016-03-27 00:22:21,719 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1614892355_0001_m_000002_0 decomp: 62 len: 66 to MEMORY
2016-03-27 00:22:21,727 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 62 bytes from map-output for attempt_local1614892355_0001_m_000002_0
2016-03-27 00:22:21,728 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 62, inMemoryMapOutputs.size() -> 5, commitMemory -> 212, usedMemory ->274
2016-03-27 00:22:21,730 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-03-27 00:22:21,732 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:22:21,733 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 0 on-disk map-outputs
2016-03-27 00:22:21,811 INFO org.apache.hadoop.mapred.Merger: Merging 5 sorted segments
2016-03-27 00:22:21,812 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 4 segments left of total size: 24 bytes
2016-03-27 00:22:21,816 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 5 segments, 274 bytes to disk to satisfy reduce memory limit
2016-03-27 00:22:21,816 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 270 bytes from disk
2016-03-27 00:22:21,817 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-03-27 00:22:21,819 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-03-27 00:22:21,820 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 212 bytes
2016-03-27 00:22:21,821 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:22:21,860 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-03-27 00:22:22,077 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1614892355_0001_r_000000_0 is done. And is in the process of committing
2016-03-27 00:22:22,085 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:22:22,087 INFO org.apache.hadoop.mapred.Task: Task attempt_local1614892355_0001_r_000000_0 is allowed to commit now
2016-03-27 00:22:22,102 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1614892355_0001_r_000000_0' to hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweetsoutput/3/_temporary/0/task_local1614892355_0001_r_000000
2016-03-27 00:22:22,103 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-03-27 00:22:22,104 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1614892355_0001_r_000000_0' done.
2016-03-27 00:22:22,104 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1614892355_0001_r_000000_0
2016-03-27 00:22:22,104 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1614892355_0001_r_000001_0
2016-03-27 00:22:22,107 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:22:22,108 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-27 00:22:22,108 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5295ea35
2016-03-27 00:22:22,109 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=1050129216, maxSingleShuffleLimit=262532304, mergeThreshold=693085312, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-03-27 00:22:22,111 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1614892355_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2016-03-27 00:22:22,115 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1614892355_0001_m_000004_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:22:22,116 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1614892355_0001_m_000004_0
2016-03-27 00:22:22,116 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2016-03-27 00:22:22,119 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1614892355_0001_m_000000_0 decomp: 51 len: 55 to MEMORY
2016-03-27 00:22:22,119 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 51 bytes from map-output for attempt_local1614892355_0001_m_000000_0
2016-03-27 00:22:22,120 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 51, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->53
2016-03-27 00:22:22,122 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1614892355_0001_m_000003_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:22:22,122 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1614892355_0001_m_000003_0
2016-03-27 00:22:22,122 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 53, usedMemory ->55
2016-03-27 00:22:22,128 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1614892355_0001_m_000001_0 decomp: 66 len: 70 to MEMORY
2016-03-27 00:22:22,129 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 66 bytes from map-output for attempt_local1614892355_0001_m_000001_0
2016-03-27 00:22:22,130 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 66, inMemoryMapOutputs.size() -> 4, commitMemory -> 55, usedMemory ->121
2016-03-27 00:22:22,133 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1614892355_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:22:22,133 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1614892355_0001_m_000002_0
2016-03-27 00:22:22,134 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 5, commitMemory -> 121, usedMemory ->123
2016-03-27 00:22:22,134 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-03-27 00:22:22,135 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:22:22,135 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 0 on-disk map-outputs
2016-03-27 00:22:22,141 INFO org.apache.hadoop.mapred.Merger: Merging 5 sorted segments
2016-03-27 00:22:22,143 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 12 bytes
2016-03-27 00:22:22,144 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 5 segments, 123 bytes to disk to satisfy reduce memory limit
2016-03-27 00:22:22,145 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 119 bytes from disk
2016-03-27 00:22:22,146 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-03-27 00:22:22,146 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-03-27 00:22:22,146 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 70 bytes
2016-03-27 00:22:22,147 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:22:22,171 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1614892355_0001_r_000001_0 is done. And is in the process of committing
2016-03-27 00:22:22,175 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:22:22,176 INFO org.apache.hadoop.mapred.Task: Task attempt_local1614892355_0001_r_000001_0 is allowed to commit now
2016-03-27 00:22:22,190 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1614892355_0001_r_000001_0' to hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweetsoutput/3/_temporary/0/task_local1614892355_0001_r_000001
2016-03-27 00:22:22,192 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-03-27 00:22:22,192 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1614892355_0001_r_000001_0' done.
2016-03-27 00:22:22,192 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1614892355_0001_r_000001_0
2016-03-27 00:22:22,193 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1614892355_0001_r_000002_0
2016-03-27 00:22:22,195 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:22:22,196 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-27 00:22:22,196 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6ca221b0
2016-03-27 00:22:22,197 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=1050129216, maxSingleShuffleLimit=262532304, mergeThreshold=693085312, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-03-27 00:22:22,199 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1614892355_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2016-03-27 00:22:22,201 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1614892355_0001_m_000004_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:22:22,203 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1614892355_0001_m_000004_0
2016-03-27 00:22:22,203 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2016-03-27 00:22:22,205 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1614892355_0001_m_000000_0 decomp: 122 len: 126 to MEMORY
2016-03-27 00:22:22,206 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 122 bytes from map-output for attempt_local1614892355_0001_m_000000_0
2016-03-27 00:22:22,206 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 122, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->124
2016-03-27 00:22:22,208 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1614892355_0001_m_000003_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:22:22,209 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1614892355_0001_m_000003_0
2016-03-27 00:22:22,209 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 124, usedMemory ->126
2016-03-27 00:22:22,214 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1614892355_0001_m_000001_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:22:22,215 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1614892355_0001_m_000001_0
2016-03-27 00:22:22,215 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 4, commitMemory -> 126, usedMemory ->128
2016-03-27 00:22:22,218 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1614892355_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:22:22,218 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1614892355_0001_m_000002_0
2016-03-27 00:22:22,219 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 5, commitMemory -> 128, usedMemory ->130
2016-03-27 00:22:22,219 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-03-27 00:22:22,220 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:22:22,220 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 0 on-disk map-outputs
2016-03-27 00:22:22,223 INFO org.apache.hadoop.mapred.Merger: Merging 5 sorted segments
2016-03-27 00:22:22,223 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 60 bytes
2016-03-27 00:22:22,224 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 5 segments, 130 bytes to disk to satisfy reduce memory limit
2016-03-27 00:22:22,225 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 126 bytes from disk
2016-03-27 00:22:22,225 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-03-27 00:22:22,225 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-03-27 00:22:22,225 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 60 bytes
2016-03-27 00:22:22,226 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:22:22,278 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1614892355_0001_r_000002_0 is done. And is in the process of committing
2016-03-27 00:22:22,289 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:22:22,290 INFO org.apache.hadoop.mapred.Task: Task attempt_local1614892355_0001_r_000002_0 is allowed to commit now
2016-03-27 00:22:22,303 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1614892355_0001_r_000002_0' to hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweetsoutput/3/_temporary/0/task_local1614892355_0001_r_000002
2016-03-27 00:22:22,305 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-03-27 00:22:22,305 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1614892355_0001_r_000002_0' done.
2016-03-27 00:22:22,306 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1614892355_0001_r_000002_0
2016-03-27 00:22:22,306 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1614892355_0001_r_000003_0
2016-03-27 00:22:22,311 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:22:22,313 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-27 00:22:22,313 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6563068f
2016-03-27 00:22:22,314 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=1050129216, maxSingleShuffleLimit=262532304, mergeThreshold=693085312, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-03-27 00:22:22,317 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1614892355_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2016-03-27 00:22:22,320 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1614892355_0001_m_000004_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:22:22,321 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1614892355_0001_m_000004_0
2016-03-27 00:22:22,321 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2016-03-27 00:22:22,323 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1614892355_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:22:22,324 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1614892355_0001_m_000000_0
2016-03-27 00:22:22,324 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->4
2016-03-27 00:22:22,326 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1614892355_0001_m_000003_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:22:22,327 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1614892355_0001_m_000003_0
2016-03-27 00:22:22,327 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 4, usedMemory ->6
2016-03-27 00:22:22,329 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1614892355_0001_m_000001_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:22:22,330 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1614892355_0001_m_000001_0
2016-03-27 00:22:22,330 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 4, commitMemory -> 6, usedMemory ->8
2016-03-27 00:22:22,332 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1614892355_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:22:22,332 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1614892355_0001_m_000002_0
2016-03-27 00:22:22,332 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 5, commitMemory -> 8, usedMemory ->10
2016-03-27 00:22:22,333 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-03-27 00:22:22,334 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:22:22,334 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 0 on-disk map-outputs
2016-03-27 00:22:22,337 INFO org.apache.hadoop.mapred.Merger: Merging 5 sorted segments
2016-03-27 00:22:22,338 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-03-27 00:22:22,339 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 5 segments, 10 bytes to disk to satisfy reduce memory limit
2016-03-27 00:22:22,339 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
2016-03-27 00:22:22,340 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-03-27 00:22:22,340 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-03-27 00:22:22,340 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-03-27 00:22:22,341 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:22:22,351 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1614892355_0001_r_000003_0 is done. And is in the process of committing
2016-03-27 00:22:22,355 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:22:22,355 INFO org.apache.hadoop.mapred.Task: Task attempt_local1614892355_0001_r_000003_0 is allowed to commit now
2016-03-27 00:22:22,363 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1614892355_0001_r_000003_0' to hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweetsoutput/3/_temporary/0/task_local1614892355_0001_r_000003
2016-03-27 00:22:22,365 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-03-27 00:22:22,365 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1614892355_0001_r_000003_0' done.
2016-03-27 00:22:22,365 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1614892355_0001_r_000003_0
2016-03-27 00:22:22,366 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-03-27 00:22:22,943 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2016-03-27 00:22:22,945 INFO org.apache.hadoop.mapreduce.Job: Job job_local1614892355_0001 completed successfully
2016-03-27 00:22:23,022 INFO org.apache.hadoop.mapreduce.Job: Counters: 38
	File System Counters
		FILE: Number of bytes read=144276
		FILE: Number of bytes written=2486392
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=111474
		HDFS: Number of bytes written=1531
		HDFS: Number of read operations=136
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=29
	Map-Reduce Framework
		Map input records=8
		Map output records=8
		Map output bytes=481
		Map output materialized bytes=617
		Input split bytes=735
		Combine input records=0
		Combine output records=0
		Reduce input groups=8
		Reduce shuffle bytes=617
		Reduce input records=8
		Reduce output records=8
		Spilled Records=16
		Shuffled Maps =20
		Failed Shuffles=0
		Merged Map outputs=20
		GC time elapsed (ms)=372
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=1844219904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=14619
	File Output Format Counters 
		Bytes Written=465
2016-03-27 00:26:34,181 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-03-27 00:26:36,559 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-03-27 00:26:36,561 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-03-27 00:26:37,415 WARN org.apache.hadoop.mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-03-27 00:26:37,571 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 5
2016-03-27 00:26:37,640 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:5
2016-03-27 00:26:37,688 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
2016-03-27 00:26:37,693 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2016-03-27 00:26:38,093 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local891821945_0001
2016-03-27 00:26:38,922 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-03-27 00:26:38,923 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local891821945_0001
2016-03-27 00:26:38,931 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-03-27 00:26:38,952 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:26:38,958 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-03-27 00:26:39,207 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-03-27 00:26:39,211 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local891821945_0001_m_000000_0
2016-03-27 00:26:39,323 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:26:39,350 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-27 00:26:39,357 INFO org.apache.hadoop.mapred.MapTask: Processing split: hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweets/FlumeData.1459060167157:0+5477
2016-03-27 00:26:39,570 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-03-27 00:26:39,570 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-03-27 00:26:39,570 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-03-27 00:26:39,571 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-03-27 00:26:39,571 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-03-27 00:26:39,581 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-03-27 00:26:39,800 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-03-27 00:26:39,813 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-03-27 00:26:39,814 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-03-27 00:26:39,814 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 247; bufvoid = 104857600
2016-03-27 00:26:39,814 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
2016-03-27 00:26:39,844 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-03-27 00:26:39,850 INFO org.apache.hadoop.mapred.Task: Task:attempt_local891821945_0001_m_000000_0 is done. And is in the process of committing
2016-03-27 00:26:39,864 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-03-27 00:26:39,865 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local891821945_0001_m_000000_0' done.
2016-03-27 00:26:39,865 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local891821945_0001_m_000000_0
2016-03-27 00:26:39,865 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local891821945_0001_m_000001_0
2016-03-27 00:26:39,867 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:26:39,868 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-27 00:26:39,870 INFO org.apache.hadoop.mapred.MapTask: Processing split: hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweets/FlumeData.1459060234833:0+3628
2016-03-27 00:26:39,952 INFO org.apache.hadoop.mapreduce.Job: Job job_local891821945_0001 running in uber mode : false
2016-03-27 00:26:39,975 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-03-27 00:26:39,984 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-03-27 00:26:39,985 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-03-27 00:26:39,985 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-03-27 00:26:39,985 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-03-27 00:26:39,985 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-03-27 00:26:39,989 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-03-27 00:26:40,009 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-03-27 00:26:40,010 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-03-27 00:26:40,010 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-03-27 00:26:40,011 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 174; bufvoid = 104857600
2016-03-27 00:26:40,011 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
2016-03-27 00:26:40,013 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-03-27 00:26:40,016 INFO org.apache.hadoop.mapred.Task: Task:attempt_local891821945_0001_m_000001_0 is done. And is in the process of committing
2016-03-27 00:26:40,021 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-03-27 00:26:40,021 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local891821945_0001_m_000001_0' done.
2016-03-27 00:26:40,021 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local891821945_0001_m_000001_0
2016-03-27 00:26:40,022 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local891821945_0001_m_000002_0
2016-03-27 00:26:40,023 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:26:40,024 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-27 00:26:40,026 INFO org.apache.hadoop.mapred.MapTask: Processing split: hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweets/FlumeData.1459061216210:0+1863
2016-03-27 00:26:40,135 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-03-27 00:26:40,141 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-03-27 00:26:40,141 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-03-27 00:26:40,141 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-03-27 00:26:40,141 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-03-27 00:26:40,146 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-03-27 00:26:40,160 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-03-27 00:26:40,160 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-03-27 00:26:40,160 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-03-27 00:26:40,160 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 86; bufvoid = 104857600
2016-03-27 00:26:40,161 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
2016-03-27 00:26:40,190 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-03-27 00:26:40,199 INFO org.apache.hadoop.mapred.Task: Task:attempt_local891821945_0001_m_000002_0 is done. And is in the process of committing
2016-03-27 00:26:40,204 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-03-27 00:26:40,205 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local891821945_0001_m_000002_0' done.
2016-03-27 00:26:40,205 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local891821945_0001_m_000002_0
2016-03-27 00:26:40,205 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local891821945_0001_m_000003_0
2016-03-27 00:26:40,207 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:26:40,208 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-27 00:26:40,213 INFO org.apache.hadoop.mapred.MapTask: Processing split: hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweets/FlumeData.1459060958922:0+1861
2016-03-27 00:26:40,317 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-03-27 00:26:40,321 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-03-27 00:26:40,321 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-03-27 00:26:40,322 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-03-27 00:26:40,322 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-03-27 00:26:40,327 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-03-27 00:26:40,344 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-03-27 00:26:40,344 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-03-27 00:26:40,345 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-03-27 00:26:40,345 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 84; bufvoid = 104857600
2016-03-27 00:26:40,346 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
2016-03-27 00:26:40,351 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-03-27 00:26:40,355 INFO org.apache.hadoop.mapred.Task: Task:attempt_local891821945_0001_m_000003_0 is done. And is in the process of committing
2016-03-27 00:26:40,367 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-03-27 00:26:40,367 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local891821945_0001_m_000003_0' done.
2016-03-27 00:26:40,372 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local891821945_0001_m_000003_0
2016-03-27 00:26:40,373 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local891821945_0001_m_000004_0
2016-03-27 00:26:40,383 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:26:40,385 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-27 00:26:40,389 INFO org.apache.hadoop.mapred.MapTask: Processing split: hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweets/FlumeData.1459060110407:0+1790
2016-03-27 00:26:40,507 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-03-27 00:26:40,508 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-03-27 00:26:40,508 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-03-27 00:26:40,508 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-03-27 00:26:40,508 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-03-27 00:26:40,509 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-03-27 00:26:40,518 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-03-27 00:26:40,519 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-03-27 00:26:40,519 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-03-27 00:26:40,519 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 114; bufvoid = 104857600
2016-03-27 00:26:40,519 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
2016-03-27 00:26:40,521 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-03-27 00:26:40,554 INFO org.apache.hadoop.mapred.Task: Task:attempt_local891821945_0001_m_000004_0 is done. And is in the process of committing
2016-03-27 00:26:40,564 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-03-27 00:26:40,565 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local891821945_0001_m_000004_0' done.
2016-03-27 00:26:40,565 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local891821945_0001_m_000004_0
2016-03-27 00:26:40,565 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-03-27 00:26:40,582 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-03-27 00:26:40,582 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local891821945_0001_r_000000_0
2016-03-27 00:26:40,596 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:26:40,598 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-27 00:26:40,603 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@28afec63
2016-03-27 00:26:40,620 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=1050129216, maxSingleShuffleLimit=262532304, mergeThreshold=693085312, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-03-27 00:26:40,629 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local891821945_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-03-27 00:26:40,696 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local891821945_0001_m_000004_0 decomp: 118 len: 122 to MEMORY
2016-03-27 00:26:40,706 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 118 bytes from map-output for attempt_local891821945_0001_m_000004_0
2016-03-27 00:26:40,715 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 118, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->118
2016-03-27 00:26:40,724 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local891821945_0001_m_000001_0 decomp: 88 len: 92 to MEMORY
2016-03-27 00:26:40,724 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 88 bytes from map-output for attempt_local891821945_0001_m_000001_0
2016-03-27 00:26:40,725 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 88, inMemoryMapOutputs.size() -> 2, commitMemory -> 118, usedMemory ->206
2016-03-27 00:26:40,727 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local891821945_0001_m_000003_0 decomp: 88 len: 92 to MEMORY
2016-03-27 00:26:40,728 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 88 bytes from map-output for attempt_local891821945_0001_m_000003_0
2016-03-27 00:26:40,728 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 88, inMemoryMapOutputs.size() -> 3, commitMemory -> 206, usedMemory ->294
2016-03-27 00:26:40,731 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local891821945_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:26:40,732 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local891821945_0001_m_000000_0
2016-03-27 00:26:40,732 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 4, commitMemory -> 294, usedMemory ->296
2016-03-27 00:26:40,734 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local891821945_0001_m_000002_0 decomp: 90 len: 94 to MEMORY
2016-03-27 00:26:40,735 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 90 bytes from map-output for attempt_local891821945_0001_m_000002_0
2016-03-27 00:26:40,735 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 90, inMemoryMapOutputs.size() -> 5, commitMemory -> 296, usedMemory ->386
2016-03-27 00:26:40,735 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-03-27 00:26:40,737 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:26:40,737 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 0 on-disk map-outputs
2016-03-27 00:26:40,746 INFO org.apache.hadoop.mapred.Merger: Merging 5 sorted segments
2016-03-27 00:26:40,746 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 4 segments left of total size: 24 bytes
2016-03-27 00:26:40,747 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 5 segments, 386 bytes to disk to satisfy reduce memory limit
2016-03-27 00:26:40,748 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 382 bytes from disk
2016-03-27 00:26:40,749 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-03-27 00:26:40,749 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-03-27 00:26:40,750 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 296 bytes
2016-03-27 00:26:40,750 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:26:40,792 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-03-27 00:26:40,941 INFO org.apache.hadoop.mapred.Task: Task:attempt_local891821945_0001_r_000000_0 is done. And is in the process of committing
2016-03-27 00:26:40,956 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:26:40,957 INFO org.apache.hadoop.mapred.Task: Task attempt_local891821945_0001_r_000000_0 is allowed to commit now
2016-03-27 00:26:40,972 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local891821945_0001_r_000000_0' to hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweetsoutput/4/_temporary/0/task_local891821945_0001_r_000000
2016-03-27 00:26:40,974 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-03-27 00:26:40,974 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local891821945_0001_r_000000_0' done.
2016-03-27 00:26:40,974 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local891821945_0001_r_000000_0
2016-03-27 00:26:40,975 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local891821945_0001_r_000001_0
2016-03-27 00:26:40,979 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:26:40,980 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-27 00:26:40,980 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2016-03-27 00:26:40,981 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@44b9146f
2016-03-27 00:26:40,982 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=1050129216, maxSingleShuffleLimit=262532304, mergeThreshold=693085312, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-03-27 00:26:40,985 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local891821945_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
2016-03-27 00:26:40,989 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local891821945_0001_m_000004_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:26:40,990 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local891821945_0001_m_000004_0
2016-03-27 00:26:40,991 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2016-03-27 00:26:40,998 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local891821945_0001_m_000001_0 decomp: 94 len: 98 to MEMORY
2016-03-27 00:26:41,001 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 94 bytes from map-output for attempt_local891821945_0001_m_000001_0
2016-03-27 00:26:41,001 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 94, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->96
2016-03-27 00:26:41,004 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local891821945_0001_m_000003_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:26:41,005 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local891821945_0001_m_000003_0
2016-03-27 00:26:41,005 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 96, usedMemory ->98
2016-03-27 00:26:41,014 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local891821945_0001_m_000000_0 decomp: 79 len: 83 to MEMORY
2016-03-27 00:26:41,015 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 79 bytes from map-output for attempt_local891821945_0001_m_000000_0
2016-03-27 00:26:41,015 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 79, inMemoryMapOutputs.size() -> 4, commitMemory -> 98, usedMemory ->177
2016-03-27 00:26:41,022 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local891821945_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:26:41,023 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local891821945_0001_m_000002_0
2016-03-27 00:26:41,023 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 5, commitMemory -> 177, usedMemory ->179
2016-03-27 00:26:41,023 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-03-27 00:26:41,025 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:26:41,026 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 0 on-disk map-outputs
2016-03-27 00:26:41,033 INFO org.apache.hadoop.mapred.Merger: Merging 5 sorted segments
2016-03-27 00:26:41,034 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 12 bytes
2016-03-27 00:26:41,035 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 5 segments, 179 bytes to disk to satisfy reduce memory limit
2016-03-27 00:26:41,035 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 175 bytes from disk
2016-03-27 00:26:41,036 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-03-27 00:26:41,036 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-03-27 00:26:41,036 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 98 bytes
2016-03-27 00:26:41,037 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:26:41,149 INFO org.apache.hadoop.mapred.Task: Task:attempt_local891821945_0001_r_000001_0 is done. And is in the process of committing
2016-03-27 00:26:41,167 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:26:41,168 INFO org.apache.hadoop.mapred.Task: Task attempt_local891821945_0001_r_000001_0 is allowed to commit now
2016-03-27 00:26:41,180 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local891821945_0001_r_000001_0' to hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweetsoutput/4/_temporary/0/task_local891821945_0001_r_000001
2016-03-27 00:26:41,181 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-03-27 00:26:41,182 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local891821945_0001_r_000001_0' done.
2016-03-27 00:26:41,182 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local891821945_0001_r_000001_0
2016-03-27 00:26:41,182 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local891821945_0001_r_000002_0
2016-03-27 00:26:41,186 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:26:41,188 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-27 00:26:41,188 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6af649f2
2016-03-27 00:26:41,192 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=1050129216, maxSingleShuffleLimit=262532304, mergeThreshold=693085312, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-03-27 00:26:41,198 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local891821945_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
2016-03-27 00:26:41,208 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local891821945_0001_m_000004_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:26:41,210 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local891821945_0001_m_000004_0
2016-03-27 00:26:41,212 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2016-03-27 00:26:41,215 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local891821945_0001_m_000001_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:26:41,219 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local891821945_0001_m_000001_0
2016-03-27 00:26:41,219 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->4
2016-03-27 00:26:41,221 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local891821945_0001_m_000003_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:26:41,225 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local891821945_0001_m_000003_0
2016-03-27 00:26:41,225 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 4, usedMemory ->6
2016-03-27 00:26:41,234 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local891821945_0001_m_000000_0 decomp: 178 len: 182 to MEMORY
2016-03-27 00:26:41,235 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 178 bytes from map-output for attempt_local891821945_0001_m_000000_0
2016-03-27 00:26:41,235 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 178, inMemoryMapOutputs.size() -> 4, commitMemory -> 6, usedMemory ->184
2016-03-27 00:26:41,237 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local891821945_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:26:41,238 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local891821945_0001_m_000002_0
2016-03-27 00:26:41,240 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 5, commitMemory -> 184, usedMemory ->186
2016-03-27 00:26:41,241 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-03-27 00:26:41,242 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:26:41,242 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 0 on-disk map-outputs
2016-03-27 00:26:41,244 INFO org.apache.hadoop.mapred.Merger: Merging 5 sorted segments
2016-03-27 00:26:41,245 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 88 bytes
2016-03-27 00:26:41,245 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 5 segments, 186 bytes to disk to satisfy reduce memory limit
2016-03-27 00:26:41,265 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 182 bytes from disk
2016-03-27 00:26:41,266 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-03-27 00:26:41,267 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-03-27 00:26:41,267 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 88 bytes
2016-03-27 00:26:41,269 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:26:41,323 INFO org.apache.hadoop.mapred.Task: Task:attempt_local891821945_0001_r_000002_0 is done. And is in the process of committing
2016-03-27 00:26:41,328 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:26:41,335 INFO org.apache.hadoop.mapred.Task: Task attempt_local891821945_0001_r_000002_0 is allowed to commit now
2016-03-27 00:26:41,348 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local891821945_0001_r_000002_0' to hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweetsoutput/4/_temporary/0/task_local891821945_0001_r_000002
2016-03-27 00:26:41,350 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-03-27 00:26:41,353 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local891821945_0001_r_000002_0' done.
2016-03-27 00:26:41,354 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local891821945_0001_r_000002_0
2016-03-27 00:26:41,355 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local891821945_0001_r_000003_0
2016-03-27 00:26:41,358 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-03-27 00:26:41,360 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-03-27 00:26:41,365 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@162d649f
2016-03-27 00:26:41,369 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=1050129216, maxSingleShuffleLimit=262532304, mergeThreshold=693085312, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-03-27 00:26:41,377 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local891821945_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
2016-03-27 00:26:41,383 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local891821945_0001_m_000004_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:26:41,384 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local891821945_0001_m_000004_0
2016-03-27 00:26:41,384 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
2016-03-27 00:26:41,388 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local891821945_0001_m_000001_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:26:41,391 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local891821945_0001_m_000001_0
2016-03-27 00:26:41,394 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->4
2016-03-27 00:26:41,397 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local891821945_0001_m_000003_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:26:41,398 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local891821945_0001_m_000003_0
2016-03-27 00:26:41,398 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 4, usedMemory ->6
2016-03-27 00:26:41,403 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local891821945_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:26:41,404 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local891821945_0001_m_000000_0
2016-03-27 00:26:41,404 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 4, commitMemory -> 6, usedMemory ->8
2016-03-27 00:26:41,411 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local891821945_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
2016-03-27 00:26:41,412 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local891821945_0001_m_000002_0
2016-03-27 00:26:41,412 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 5, commitMemory -> 8, usedMemory ->10
2016-03-27 00:26:41,413 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-03-27 00:26:41,414 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:26:41,415 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 5 in-memory map-outputs and 0 on-disk map-outputs
2016-03-27 00:26:41,417 INFO org.apache.hadoop.mapred.Merger: Merging 5 sorted segments
2016-03-27 00:26:41,417 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-03-27 00:26:41,418 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 5 segments, 10 bytes to disk to satisfy reduce memory limit
2016-03-27 00:26:41,420 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 6 bytes from disk
2016-03-27 00:26:41,420 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-03-27 00:26:41,420 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-03-27 00:26:41,421 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 0 segments left of total size: 0 bytes
2016-03-27 00:26:41,428 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:26:41,446 INFO org.apache.hadoop.mapred.Task: Task:attempt_local891821945_0001_r_000003_0 is done. And is in the process of committing
2016-03-27 00:26:41,450 INFO org.apache.hadoop.mapred.LocalJobRunner: 5 / 5 copied.
2016-03-27 00:26:41,452 INFO org.apache.hadoop.mapred.Task: Task attempt_local891821945_0001_r_000003_0 is allowed to commit now
2016-03-27 00:26:41,464 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local891821945_0001_r_000003_0' to hdfs://quickstart.cloudera:8020/user/cloudera/flume/tweetsoutput/4/_temporary/0/task_local891821945_0001_r_000003
2016-03-27 00:26:41,465 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-03-27 00:26:41,465 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local891821945_0001_r_000003_0' done.
2016-03-27 00:26:41,466 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local891821945_0001_r_000003_0
2016-03-27 00:26:41,466 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-03-27 00:26:41,989 INFO org.apache.hadoop.mapreduce.Job: Job job_local891821945_0001 completed successfully
2016-03-27 00:26:42,159 INFO org.apache.hadoop.mapreduce.Job: Counters: 38
	File System Counters
		FILE: Number of bytes read=177065
		FILE: Number of bytes written=2507287
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=111474
		HDFS: Number of bytes written=2259
		HDFS: Number of read operations=136
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=29
	Map-Reduce Framework
		Map input records=8
		Map output records=8
		Map output bytes=705
		Map output materialized bytes=841
		Input split bytes=735
		Combine input records=0
		Combine output records=0
		Reduce input groups=8
		Reduce shuffle bytes=841
		Reduce input records=8
		Reduce output records=8
		Spilled Records=16
		Shuffled Maps =20
		Failed Shuffles=0
		Merged Map outputs=20
		GC time elapsed (ms)=346
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=1844219904
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=14619
	File Output Format Counters 
		Bytes Written=689
